{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNqDu4ZspX+azQMJi9bs2kW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spate472/RecreatingRetinaUNet/blob/main/Attempt2_ToyDataPyHealth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyhealth pydicom scikit-image matplotlib\n",
        "!pip install pandas==2.2.2\n",
        "!pip install torch torchvision"
      ],
      "metadata": {
        "id": "Y9bEztoR_bGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import pydicom\n",
        "import pandas\n",
        "import numpy\n",
        "import pyhealth\n",
        "import skimage\n",
        "\n",
        "print(f\"pydicom: {pydicom.__version__}\")\n",
        "print(f\"pandas: {pandas.__version__}\")\n",
        "print(f\"numpy: {numpy.__version__}\")\n",
        "print(f\"pyhealth: {pyhealth.__version__}\")\n",
        "print(f\"skimage: {skimage.__version__}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "GTUwhuEuDLxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "from skimage.draw import disk\n",
        "from pyhealth.datasets.base_dataset_v2 import BaseDataset\n",
        "from pyhealth.data import Patient, Visit, Event\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import os\n",
        "import json\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# 1. Define the Custom Dataset (Extending BaseDataset)\n",
        "class ToyImageDataset(BaseDataset):\n",
        "    def __init__(self, root, task_type='shapes', dev='cpu', verbose=True, dataset_name=\"toy_images\"): #Added Dataset Name\n",
        "        self.task_type = task_type\n",
        "        self.verbose = verbose\n",
        "        self.dev = dev\n",
        "        self.image_size = 320\n",
        "        self.data_dir = root\n",
        "        if not os.path.exists(self.data_dir): #create as needed\n",
        "             os.makedirs(self.data_dir) #Create directory if needed\n",
        "        patient_list, sample_list = self.process() #Returns\n",
        "        super().__init__(dataset_name=dataset_name, sample_list=sample_list, root=root) #Run Base init\n",
        "        self.patient_list = patient_list\n",
        "        self.sample_list = sample_list\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),  # Convert to tensor (C, H, W)\n",
        "            transforms.Grayscale(num_output_channels=1),  # Convert to grayscale (1 channel)\n",
        "        ])\n",
        "\n",
        "    def process(self):\n",
        "        \"\"\"Generates and stores the toy images and labels.\n",
        "\n",
        "        This function creates the synthetic data and converts it into a list\n",
        "        of PyHealth Patient objects.\n",
        "        \"\"\"\n",
        "        if self.verbose:\n",
        "            print(\"Generating Toy Dataset...\")\n",
        "\n",
        "        patient_list = []\n",
        "        samples = []\n",
        "\n",
        "        for patient_id in range(10):  # Small number of patients\n",
        "            patient_str = str(patient_id)\n",
        "            patient = Patient(patient_id=patient_str)\n",
        "            visit = Visit(visit_id=\"visit_0\", patient_id=patient_str)\n",
        "\n",
        "            img, mask = self._generate_image_and_mask(random.randint(0, 1)) #Binary label\n",
        "            image_event = Event(visit_id=\"visit_0\", patient_id=patient_str, code=\"image\", value=torch.tensor(img, dtype=torch.float32).unsqueeze(0), vocabulary=\"imaging\")\n",
        "            mask_event =  Event(visit_id=\"visit_0\", patient_id=patient_str, code=\"mask\", value=torch.tensor(mask, dtype=torch.float32).unsqueeze(0), vocabulary=\"imaging\")\n",
        "            visit.add_event(image_event)\n",
        "            visit.add_event(mask_event)\n",
        "            patient.add_visit(visit)\n",
        "            patient_list.append(patient)\n",
        "            samples.append((patient_str, visit.visit_id)) # add tuple for dataloader.\n",
        "\n",
        "        #Create JSON dict:\n",
        "        def local_asdict(obj):\n",
        "            if hasattr(obj, '__dict__'):\n",
        "                return obj.__dict__\n",
        "            return str(obj)\n",
        "\n",
        "        dataset_dict = {\n",
        "            \"patient_list\" : patient_list,\n",
        "        }\n",
        "\n",
        "        #with open(os.path.join(self.data_dir, \"dataset.json\"), 'w') as f:\n",
        "        #   json.dump([local_asdict(p) for p in patient_list], f, indent=4) # save as dict, with indent\n",
        "\n",
        "        return patient_list, samples\n",
        "\n",
        "    def _generate_image_and_mask(self, label):\n",
        "         img = np.zeros((self.image_size, self.image_size), dtype=np.float32)\n",
        "         r = 20\n",
        "         x, y = random.randint(40, 280), random.randint(40, 280) #Image Limits\n",
        "         rr, cc = disk((x, y), r, shape=(self.image_size, self.image_size)) #Shape\n",
        "         img[rr, cc] = 0.2  #Intensity\n",
        "\n",
        "         if self.task_type == 'shapes' and label == 1:\n",
        "             rr_inner, cc_inner = disk((x, y), r // 2, shape=(self.image_size, self.image_size))\n",
        "             img[rr_inner, cc_inner] -= 0.2\n",
        "\n",
        "         img += np.random.uniform(0, 0.05, img.shape) # Noise\n",
        "         return img, img  # image and mask\n",
        "\n",
        "    def __len__(self): #BaseDataset now has to know how many samples you have\n",
        "        return len(self.sample_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            idx: The index of the sample to fetch.\n",
        "        Returns:\n",
        "            A dict of features and labels.\n",
        "        \"\"\"\n",
        "        patient_id, visit_id = self.sample_list[idx]\n",
        "\n",
        "        #Manually Iterating and using get_event_list\n",
        "        patient = next(p for p in self.patient_list if p.patient_id == patient_id)\n",
        "        image = None\n",
        "        mask = None\n",
        "        for visit in patient.visits:\n",
        "             if visit == visit_id:\n",
        "                print(patient.visits[visit])\n",
        "                print(patient.visits[visit].get_event_list(None))\n",
        "\n",
        "                image_events = visit.get_event_list(code=\"image\")\n",
        "                mask_events = visit.get_event_list(code=\"mask\")\n",
        "\n",
        "                if image_events:\n",
        "                    image = image_events[0].value\n",
        "                if mask_events:\n",
        "                    mask = mask_events[0].value\n",
        "\n",
        "        if image is None or mask is None:\n",
        "            print(f\"Warning: Missing data for patient {patient_id}, visit code{visit_id}\")\n",
        "            image = torch.zeros((1, self.image_size, self.image_size)) #Make sure it is not error\n",
        "            mask = torch.zeros((1, self.image_size, self.image_size))\n",
        "        image = self.transform(image)\n",
        "        mask = self.transform(mask)\n",
        "\n",
        "        mask = mask / mask.max()  # Normalize mask to 0-1 range\n",
        "\n",
        "        return {\n",
        "            \"image\": image,\n",
        "            \"mask\": mask,\n",
        "        }\n",
        "\n",
        "    def stat(self):\n",
        "         print(\"Stat method was called\")\n",
        "         return None\n",
        "\n",
        "# 2. Model and Training Loop (Mostly Unchanged) - Same\n",
        "\n",
        "# 2. Define a simplified RetinaUNet-like model (adapted for toy data)\n",
        "class RetinaUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RetinaUNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.deconv1 = nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2)\n",
        "        self.deconv2 = nn.ConvTranspose2d(16, 1, kernel_size=(2, 2))\n",
        "        self.fc1 = nn.Linear(32 * 80 * 80, 64)  # Adjusted to match feature map size\n",
        "        self.fc2 = nn.Linear(64, 32 * 80 * 80)  # Changed to output the correct number of units\n",
        "\n",
        "    def forward(self, image):\n",
        "        # Encoding path\n",
        "        x = self.pool(F.relu(self.conv1(image)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "\n",
        "        # Flatten for the fully connected layers\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        logits = self.fc2(x)\n",
        "\n",
        "        # Reshape output to match original image size\n",
        "        logits = logits.view(logits.size(0), 32, 80, 80)  # Reshape it to a 4D tensor\n",
        "\n",
        "        # Add deconvolution layers for segmentation output\n",
        "        x = self.deconv1(logits)\n",
        "        x = self.deconv2(x)\n",
        "\n",
        "        x = torch.sigmoid(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# 3. Main execution block\n",
        "DATA_DIR = \"/content/toy_dataset\"\n",
        "dataset = ToyImageDataset(root=DATA_DIR, task_type='shapes')\n",
        "\n",
        "# Splitting data into train, validation, and test sets\n",
        "train_size = int(0.6 * len(dataset))\n",
        "val_size = int(0.2 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "#Load data into a dataloader\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "device = 'cpu'\n",
        "\n",
        "# 4. Model\n",
        "model = RetinaUNet().to(device) #Create Model\n",
        "\n",
        "# Define optimizer and criterion\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss() # more stable\n",
        "\n",
        "#---------------------------------------------------------------------------------------\n",
        "#Training Function\n",
        "def train_epoch(model, dataloader, optimizer, criterion, epoch, device):\n",
        "    model.train() #Set to train\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(dataloader):\n",
        "        images = data[\"image\"].to(device) #load to mem\n",
        "        masks = data[\"mask\"].to(device) #load to mem\n",
        "        optimizer.zero_grad() #Zero optimizer\n",
        "        outputs = model(images) #Set data to training function\n",
        "        loss = criterion(outputs, masks) #Set training loss\n",
        "        loss.backward() #Update with backpropigation\n",
        "        optimizer.step() #Advance the data\n",
        "        running_loss += loss.item() #Add to total\n",
        "\n",
        "    print(f'Epoch {epoch} - Training Loss: {running_loss/len(dataloader)}')#Show in process\n",
        "#---------------------------------------------------------------------------------------\n",
        "#Evaluation Function\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    dice_score = 0.0\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(dataloader):\n",
        "            images = data[\"image\"].to(device)\n",
        "            masks = data[\"mask\"].to(device)\n",
        "            outputs = model(images)\n",
        "            dice_score += dice_coefficient(outputs, masks).item()\n",
        "    avg_dice = dice_score/len(dataloader)\n",
        "    print(f'Test Dice Score: {avg_dice}')\n",
        "    return avg_dice\n",
        "\n",
        "#---------------------------------------------------------------------------------------\n",
        "#Helper Function\n",
        "def dice_coefficient(pred, target, threshold=0.5):\n",
        "    pred = (pred > threshold).float()\n",
        "    target = (target > threshold).float()\n",
        "    intersection = torch.sum(pred * target)\n",
        "    union = torch.sum(pred) + torch.sum(target)\n",
        "    return 2.0 * intersection / (union + 1e-6)\n",
        "\n",
        "# 5. Training and Evaluation Loop\n",
        "num_epochs = 10 #Training Steps\n",
        "for epoch in range(num_epochs):\n",
        "    train_epoch(model, train_loader, optimizer, criterion, epoch, device) #Run train, data, other params\n",
        "\n",
        "evaluate_model(model, test_loader, device) #Run Evaluate Loop"
      ],
      "metadata": {
        "id": "kxQtWgRLkd7A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}