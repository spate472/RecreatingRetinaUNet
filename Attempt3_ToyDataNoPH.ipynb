{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spate472/RecreatingRetinaUNet/blob/main/Attempt3_ToyDataNoPH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65ui7Wtrbk_u"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir4HPEs6ZyZW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# ToyDataset class\n",
        "class ToyDataset(Dataset):\n",
        "    def __init__(self, num_samples=1000, image_size=(320, 320), noise_factor=0.2, transform=None):\n",
        "        self.num_samples = num_samples\n",
        "        self.image_size = image_size\n",
        "        self.noise_factor = noise_factor\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Create a blank image (black background)\n",
        "        image = np.zeros((320, 320, 3), dtype=np.uint8)\n",
        "\n",
        "        # Randomly choose shape type: 0 = circle, 1 = donut\n",
        "        shape_type = random.randint(0, 1)\n",
        "\n",
        "        # Random center and radius\n",
        "        center_x = random.randint(64, 256)\n",
        "        center_y = random.randint(64, 256)\n",
        "        radius = random.randint(20, 40)\n",
        "\n",
        "        # Define custom colors\n",
        "        color = (random.randint(0, 100), random.randint(100, 255), random.randint(200, 255))\n",
        "\n",
        "        # Draw the shape on the image\n",
        "        if shape_type == 0:\n",
        "            # Draw filled circle\n",
        "            cv2.circle(image, (center_x, center_y), radius, color, -1)\n",
        "        else:\n",
        "            # Draw ring\n",
        "            cv2.circle(image, (center_x, center_y), radius, color, 3)\n",
        "            cv2.circle(image, (center_x, center_y), radius - 10, (0, 0, 0), -1)\n",
        "\n",
        "        # Generate noise with a blue hue, but with a slightly darker blue background\n",
        "        noise = np.random.uniform(low=0, high=self.noise_factor, size=(320, 320, 3))\n",
        "\n",
        "        # Create a background that is a little darker than the circle's color\n",
        "        noise[..., 0] += np.random.uniform(0.0, 0.1, (320, 320))  # Slightly darker blue\n",
        "        noise[..., 1] += np.random.uniform(0.0, 0.2, (320, 320))  # Slight green variation\n",
        "        noise[..., 2] += np.random.uniform(0.1, 0.3, (320, 320))  # Slight red variation\n",
        "\n",
        "        # Clip the values to ensure they stay within the valid image range (0-255)\n",
        "        noisy_image = np.clip(image + noise * 255, 0, 255).astype(np.uint8)\n",
        "\n",
        "        # Create the mask (ground truth)\n",
        "        mask = np.zeros((320, 320), dtype=np.uint8)\n",
        "        if shape_type == 0:\n",
        "            # Circle mask\n",
        "            cv2.circle(mask, (center_x, center_y), radius, 255, -1)\n",
        "        else:\n",
        "            # Donut mask\n",
        "            cv2.circle(mask, (center_x, center_y), radius, 255, 3)\n",
        "            cv2.circle(mask, (center_x, center_y), radius - 10, 0, -1)\n",
        "\n",
        "\n",
        "        # Normalize image and mask\n",
        "        noisy_image = noisy_image.astype(np.float32) / 255.0\n",
        "        mask = mask.astype(np.float32) / 255.0\n",
        "\n",
        "        # Convert to tensors\n",
        "        noisy_image = torch.from_numpy(noisy_image.transpose((2, 0, 1)))\n",
        "        mask = torch.from_numpy(mask).unsqueeze(0)\n",
        "\n",
        "        return noisy_image, mask\n",
        "\n",
        "# Baseline Model 1: Simple UNet implementation\n",
        "class SimpleUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleUNet, self).__init__()\n",
        "        # Encoder\n",
        "        self.enc_conv = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.pool = nn.AvgPool2d(2)\n",
        "\n",
        "        # Decoder\n",
        "        self.upconv = nn.ConvTranspose2d(16, 16, kernel_size=2, stride=2)\n",
        "        self.dec_conv = nn.Conv2d(16, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.enc_conv(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.upconv(x)\n",
        "        x = self.dec_conv(x)\n",
        "        return x\n",
        "\n",
        "# Baseline Model 2: Simple RetinaNet implementation\n",
        "class SimpleRetinaNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleRetinaNet, self).__init__()\n",
        "        # ResNet18 backbone\n",
        "        resnet = models.resnet18(pretrained=False)\n",
        "        # Use only up to layer3 to avoid too much downsampling\n",
        "        self.encoder = nn.Sequential(\n",
        "            resnet.conv1,\n",
        "            resnet.bn1,\n",
        "            resnet.relu,\n",
        "            resnet.maxpool,\n",
        "            resnet.layer1,\n",
        "            resnet.layer2,\n",
        "        )\n",
        "        # Neck (process feature maps)\n",
        "        self.neck = nn.Sequential(\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        # Head (predict mask)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Conv2d(32, 1, kernel_size=1)\n",
        "        )\n",
        "        # Final upsampling layer (by 8x)\n",
        "        self.upsample = nn.Upsample(scale_factor=8, mode='bilinear', align_corners=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.neck(x)\n",
        "        x = self.head(x)\n",
        "        x = self.upsample(x)\n",
        "        return x\n",
        "\n",
        "# Our implementation of the Retina U-Net Model\n",
        "class RetinaUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RetinaUNet, self).__init__()\n",
        "        resnet = models.resnet18(pretrained=False)\n",
        "\n",
        "        # Encoder layers (for skip connections)\n",
        "        self.enc1 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu)\n",
        "        self.enc2 = nn.Sequential(resnet.maxpool, resnet.layer1)\n",
        "        self.enc3 = resnet.layer2\n",
        "        self.enc4 = resnet.layer3\n",
        "        self.enc5 = resnet.layer4\n",
        "\n",
        "        # Decoder\n",
        "        self.upconv1 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.conv1 = nn.Conv2d(256 + 256, 256, kernel_size=3, padding=1)\n",
        "\n",
        "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(128 + 128, 128, kernel_size=3, padding=1)\n",
        "\n",
        "        self.upconv3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64 + 64, 64, kernel_size=3, padding=1)\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
        "        self.conv4 = nn.Conv2d(32 + 64, 32, kernel_size=3, padding=1)\n",
        "\n",
        "        self.final_conv = nn.Conv2d(32, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder with skip connections\n",
        "        x1 = self.enc1(x)\n",
        "        x2 = self.enc2(x1)\n",
        "        x3 = self.enc3(x2)\n",
        "        x4 = self.enc4(x3)\n",
        "        x5 = self.enc5(x4)\n",
        "\n",
        "        # Decoder with skip connections\n",
        "        x = self.upconv1(x5)\n",
        "        x = torch.cat([x, x4], dim=1)\n",
        "        x = F.relu(self.conv1(x))\n",
        "\n",
        "        x = self.upconv2(x)\n",
        "        x = torch.cat([x, x3], dim=1)\n",
        "        x = F.relu(self.conv2(x))\n",
        "\n",
        "        x = self.upconv3(x)\n",
        "        x = torch.cat([x, x2], dim=1)\n",
        "        x = F.relu(self.conv3(x))\n",
        "\n",
        "        x = self.upconv4(x)\n",
        "        x = torch.cat([x, x1], dim=1)\n",
        "        x = F.relu(self.conv4(x))\n",
        "\n",
        "        x = F.interpolate(x, size=(320, 320), mode='bilinear', align_corners=False)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# Training loop\n",
        "def train(model, dataloader, optimizer, device, num_epochs=5, dropout_p=0.5):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (imgs, masks) in enumerate(dataloader):\n",
        "            imgs = imgs.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            # Apply input dropout\n",
        "            if dropout_p > 0:\n",
        "                imgs = F.dropout(imgs, p=dropout_p, training=True)\n",
        "\n",
        "            # Ensure proper mask dimensions\n",
        "            if masks.ndimension() == 3:\n",
        "                masks = masks.unsqueeze(1)\n",
        "\n",
        "            # Resize masks and predictions\n",
        "            masks_resized = F.interpolate(masks.float(), size=(320, 320), mode='nearest')\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "            outputs_resized = F.interpolate(outputs, size=(320, 320), mode='nearest')\n",
        "\n",
        "            # Compute and optimize loss\n",
        "            loss = criterion(outputs_resized, masks_resized)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'>> Epoch {epoch+1}/{num_epochs}, Average Loss: {running_loss/len(dataloader):.4f}\\n')\n",
        "\n",
        "\n",
        "\n",
        "# Visualize a sample image, mask, and prediction from the model\n",
        "def visualize_samples(model, dataloader, device, num_samples=3):\n",
        "    model.eval()\n",
        "    imgs, masks = next(iter(dataloader))\n",
        "    imgs = imgs.to(device)\n",
        "    masks = masks.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.forward(imgs)\n",
        "        outputs = torch.sigmoid(outputs).squeeze().cpu()\n",
        "\n",
        "    # Create a figure with multiple subplots\n",
        "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        # Show input image\n",
        "        axes[i, 0].imshow(imgs[i].cpu().permute(1, 2, 0))\n",
        "        axes[i, 0].set_title(f'Image {i+1}')\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        # Show ground truth mask\n",
        "        gt_mask = masks[i].cpu()\n",
        "        if gt_mask.ndim == 3 and gt_mask.shape[0] == 1:\n",
        "            gt_mask = gt_mask.squeeze(0)\n",
        "        axes[i, 1].imshow(gt_mask, cmap='gray')\n",
        "        axes[i, 1].set_title(f'Ground Truth Mask {i+1}')\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "        # Show prediction\n",
        "        pred_mask = outputs[i]\n",
        "        if pred_mask.ndim == 3 and pred_mask.shape[0] == 1:\n",
        "            pred_mask = pred_mask.squeeze(0)\n",
        "        pred_mask = pred_mask.numpy()\n",
        "\n",
        "        axes[i, 2].imshow(pred_mask, cmap='gray')\n",
        "        axes[i, 2].set_title(f'Predicted Mask {i+1}')\n",
        "        axes[i, 2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Evaluating the Dice Score between the Ground Truth Mask and the Model's Prediction\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    dice_scores = []\n",
        "    with torch.no_grad():\n",
        "        for images, masks in loader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device).float()\n",
        "\n",
        "            outputs = model(images)\n",
        "            outputs = torch.sigmoid(outputs)\n",
        "            preds = (outputs > 0.5).float()\n",
        "\n",
        "            # Calculate Dice score for each sample\n",
        "            intersection = (preds * masks).sum(dim=(1,2,3))\n",
        "            union = preds.sum(dim=(1,2,3)) + masks.sum(dim=(1,2,3))\n",
        "            dice = (2. * intersection) / (union + 1e-8)\n",
        "            dice_scores.extend(dice.cpu().numpy())\n",
        "\n",
        "    # Compute average Dice score\n",
        "    mean_dice = sum(dice_scores) / len(dice_scores)\n",
        "    print(f\"Mean Dice score: {mean_dice:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xjOxalogg8E"
      },
      "outputs": [],
      "source": [
        "# Create full dataset\n",
        "full_dataset = ToyDataset(num_samples=1000)\n",
        "\n",
        "# Split into train/val\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Create loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=10, shuffle=False)\n",
        "\n",
        "# Pick Random Image and Mask's and visually displaying them\n",
        "indices = random.sample(range(len(train_dataset)), 10)\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
        "fig.suptitle(\"Random Samples: Image and Mask Side-by-Side\", fontsize=18)\n",
        "\n",
        "for ax, idx in zip(axes.flatten(), indices):\n",
        "    image, mask = train_dataset[idx]\n",
        "    image_np = image.permute(1, 2, 0).numpy()\n",
        "    mask_np = mask.squeeze().numpy()\n",
        "    if mask_np.ndim == 2:\n",
        "        mask_np = np.expand_dims(mask_np, axis=-1)\n",
        "\n",
        "    if mask_np.max() > 1:\n",
        "        mask_np = mask_np / mask_np.max()\n",
        "\n",
        "    mask_rgb = np.repeat(mask_np, 3, axis=-1)\n",
        "    combined = np.concatenate((image_np, mask_rgb), axis=1)\n",
        "    ax.imshow(combined)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(top=0.88)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpUy8OaMtsaK"
      },
      "outputs": [],
      "source": [
        "# Create model\n",
        "model = SimpleUNet()\n",
        "# Choose device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "# Set up optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "# Run training, visualizing output and evaluation\n",
        "train(model, train_loader, optimizer, device, num_epochs=5, dropout_p=0.3)\n",
        "visualize_samples(model, val_loader, device, num_samples=10)\n",
        "evaluate(model, val_loader, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEGY10328AQc"
      },
      "outputs": [],
      "source": [
        "# Create model\n",
        "model = SimpleRetinaNet()\n",
        "# Choose device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "model = model.to(device)\n",
        "# Set up optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "# Run training, visualizing output and evaluation\n",
        "train(model, train_loader, optimizer, device, num_epochs=5, dropout_p=0.3)\n",
        "visualize_samples(model, val_loader, device, num_samples=10)\n",
        "evaluate(model, val_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP2eVEAC0E3q"
      },
      "outputs": [],
      "source": [
        "# Create model\n",
        "model = RetinaUNet()\n",
        "# Choose device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "model = model.to(device)\n",
        "# Set up optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "# Run training, visualizing output and evaluation\n",
        "train(model, train_loader, optimizer, device, num_epochs=5, dropout_p=0.3)\n",
        "visualize_samples(model, val_loader, device, num_samples=10)\n",
        "evaluate(model, val_loader, device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}